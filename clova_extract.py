#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
CLOVA OCR ë¡œ bboxÂ·í…ìŠ¤íŠ¸ ì¶”ì¶œ â†’ crop ì €ì¥ & CSV ìƒì„± (ë©€í‹° ì¹´í…Œê³ ë¦¬ ë²„ì „)
------------------------------------------------------------------
INPUT  ë””ë ‰í† ë¦¬
    train_2/image, train_2/notice, train_2/handwriting
    test_2/image, test_2/notice, test_2/handwriting
OUTPUT ë””ë ‰í† ë¦¬
    CLOVA_V2_train/merged_images + CLOVA_V2_train/train_labels.csv
    CLOVA_V2_test/merged_images  + CLOVA_V2_test/test_labels.csv
"""

import os, json, base64, time, uuid, csv
from pathlib import Path
from typing import List, Dict, Tuple, Optional

import cv2
import numpy as np
import requests
from dotenv import load_dotenv
import matplotlib.pyplot as plt
import matplotlib.patches as patches

from pororo.models.brainOCR import brainocr           # Reader
from pororo.models.brainOCR.recognition import AlignCollate, ListDataset
from datasets import recognize_imgs                   # ì´ë¯¸ ì‘ì„±ë¼ ìˆìŒ


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 0.  CLOVA  OCR  í˜¸ì¶œ ìœ í‹¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def clova_ocr_api(img_path: Path, api_url: str, secret: str
                  ) -> Optional[Dict]:
    """ë‹¨ì¼ ì´ë¯¸ì§€ â†’ CLOVA OCR ê²°ê³¼(JSON)"""
    img_b64 = base64.b64encode(img_path.read_bytes()).decode()
    req = {
        "version":"V2","requestId":str(uuid.uuid4()),
        "timestamp":int(time.time()*1000),"lang":"ko",
        "images":[{"format":img_path.suffix[1:],
                   "name":img_path.stem, "data":img_b64}],
        "enableTableDetection": False
    }
    headers = {"X-OCR-SECRET": secret,
               "Content-Type":"application/json"}
    res = requests.post(api_url, headers=headers, data=json.dumps(req))
    if res.status_code==200: return res.json()
    print(f"[{img_path.name}] OCR ì‹¤íŒ¨ â†’ {res.status_code}")
    return None


def parse_fields(resp: Dict, conf_th: float = 0.5
                ) -> List[Tuple[str, float, List[Tuple[int, int]]]]:
    """
    ë°˜í™˜: [(text, confidence, bbox_vertices[4]), ...]
    bbox ëŠ” (x,y) int íŠœí”Œ 4ê°œ
    """
    if not resp or resp["images"][0]["inferResult"]!="SUCCESS": return []
    fields = resp["images"][0].get("fields",[])
    out=[]
    for f in fields:
        c = f["inferConfidence"]
        if c < conf_th: continue
        verts = [(v["x"], v["y"]) for v in
                 f["boundingPoly"]["vertices"]]
        out.append((f["inferText"], c, verts))
    return out


def expand_bbox_with_padding(verts: List[Tuple[int, int]], 
                           img_height: int, img_width: int,
                           padding_ratio: float = 0.3,
                           min_padding: int = 10) -> Tuple[int, int, int, int]:
    """
    ê°œì„ ëœ bbox í™•ì¥ í•¨ìˆ˜ (ìµœì†Œ íŒ¨ë”© ë³´ì¥)
    """
    xs, ys = zip(*[(int(x), int(y)) for x, y in verts])
    x0, y0, x1, y1 = min(xs), min(ys), max(xs), max(ys)
    
    # í˜„ì¬ bboxì˜ ë„ˆë¹„, ë†’ì´
    bbox_width = x1 - x0
    bbox_height = y1 - y0
    
    # íŒ¨ë”© ê³„ì‚° (ë¹„ìœ¨ ê¸°ë°˜ + ìµœì†Œê°’ ë³´ì¥)
    padding_x = max(min_padding, int(bbox_width * padding_ratio))
    padding_y = max(min_padding, int(bbox_height * padding_ratio))
    
    # íŒ¨ë”© ì ìš©í•˜ì—¬ í™•ì¥
    x0_padded = max(0, x0 - padding_x)
    y0_padded = max(0, y0 - padding_y)
    x1_padded = min(img_width, x1 + padding_x)
    y1_padded = min(img_height, y1 + padding_y)
    
    return x0_padded, y0_padded, x1_padded, y1_padded


def enhance_crop_quality(crop: np.ndarray, 
                        target_height: int = 64,
                        target_width: Optional[int] = None,
                        enhance_contrast: bool = True,
                        sharpen: bool = True,
                        denoise: bool = True) -> np.ndarray:
    """
    crop ì´ë¯¸ì§€ì˜ í’ˆì§ˆì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
    """
    if crop.size == 0:
        return crop
    
    # 1) ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜ (í…ìŠ¤íŠ¸ ì¸ì‹ì— ë” ì¢‹ìŒ)
    if len(crop.shape) == 3:
        gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)
    else:
        gray = crop.copy()
    
    # 2) ë…¸ì´ì¦ˆ ì œê±° (ì‘ì€ ì¡ìŒ ì œê±°)
    if denoise:
        gray = cv2.fastNlMeansDenoising(gray, h=10)
    
    # 3) ëŒ€ë¹„ í–¥ìƒ (í…ìŠ¤íŠ¸ë¥¼ ë” ì„ ëª…í•˜ê²Œ)
    if enhance_contrast:
        # CLAHE (Contrast Limited Adaptive Histogram Equalization)
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
        gray = clahe.apply(gray)
        
        # ì¶”ê°€ ëŒ€ë¹„ ì¡°ì •
        gray = cv2.convertScaleAbs(gray, alpha=1.2, beta=10)
    
    # 4) ìƒ¤í”„ë‹ (í…ìŠ¤íŠ¸ ê°€ì¥ìë¦¬ë¥¼ ë” ì„ ëª…í•˜ê²Œ)
    if sharpen:
        kernel = np.array([[-1,-1,-1],
                          [-1, 9,-1],
                          [-1,-1,-1]])
        gray = cv2.filter2D(gray, -1, kernel)
    
    # 5) í¬ê¸° ì¡°ì • (ë” í° í¬ê¸°ë¡œ ì—…ìŠ¤ì¼€ì¼ë§)
    h, w = gray.shape
    if target_width is None:
        # ì¢…íš¡ë¹„ ìœ ì§€í•˜ë©´ì„œ ë†’ì´ ê¸°ì¤€ìœ¼ë¡œ ì¡°ì •
        aspect_ratio = w / h
        target_width = int(target_height * aspect_ratio)
    
    # ì—…ìŠ¤ì¼€ì¼ë§ ì‹œ INTER_CUBIC ì‚¬ìš© (ë” ë¶€ë“œëŸ¬ìš´ ê²°ê³¼)
    if target_height > h or target_width > w:
        enhanced = cv2.resize(gray, (target_width, target_height), 
                            interpolation=cv2.INTER_CUBIC)
    else:
        enhanced = cv2.resize(gray, (target_width, target_height), 
                            interpolation=cv2.INTER_AREA)
    
    return enhanced


def save_enhanced_crop(crop: np.ndarray, 
                      save_path: str,
                      enhancement_level: str = "medium") -> bool:
    """
    í–¥ìƒëœ cropì„ ì €ì¥í•©ë‹ˆë‹¤.
    """
    if crop.size == 0:
        return False
    
    # í–¥ìƒ ìˆ˜ì¤€ë³„ ì„¤ì •
    settings = {
        "light": {
            "target_height": 64,
            "enhance_contrast": True,
            "sharpen": False,
            "denoise": False
        },
        "medium": {
            "target_height": 96,  # ë” í° í¬ê¸°
            "enhance_contrast": True,
            "sharpen": True,
            "denoise": True
        },
        "heavy": {
            "target_height": 128,  # ê°€ì¥ í° í¬ê¸°
            "enhance_contrast": True,
            "sharpen": True,
            "denoise": True
        }
    }
    
    config = settings.get(enhancement_level, settings["medium"])
    
    # ì´ë¯¸ì§€ í–¥ìƒ ì²˜ë¦¬
    enhanced = enhance_crop_quality(crop, **config)
    
    # PNGë¡œ ì €ì¥ (ë¬´ì†ì‹¤ ì••ì¶•)
    success = cv2.imwrite(save_path, enhanced, 
                         [cv2.IMWRITE_PNG_COMPRESSION, 0])  # ìµœê³  í’ˆì§ˆ
    
    return success


def is_valid_crop(text: str, crop_width: int, crop_height: int, img_width: int, img_height: int) -> Tuple[bool, str]:
    """
    cropì´ í’ˆì§ˆ ê¸°ì¤€ì„ ë§Œì¡±í•˜ëŠ”ì§€ ê²€ì‚¬ (ì´ë¯¸ì§€ í¬ê¸° ë¹„ë¡€ ë™ì  ì¡°ì •)
    """
    # í…ìŠ¤íŠ¸ ê¸¸ì´ ì²´í¬
    text_clean = text.strip()
    if len(text_clean) == 0:
        return False, f"ë¹ˆ í…ìŠ¤íŠ¸: '{text}'"
    
    # í•œ ê¸€ìì¸ ê²½ìš° íŠ¹ìˆ˜ë¬¸ìë§Œ ì œì™¸ (ìˆ«ì, ë¬¸ìëŠ” í—ˆìš©)
    if len(text_clean) == 1:
        if text_clean in 'â†’-ã†.,;(){}[]<>\\~`\'\"_=+!?@#$%^&*|/':
            return False, f"ì˜ë¯¸ì—†ëŠ” íŠ¹ìˆ˜ë¬¸ì: '{text}'"
    
    if len(text_clean) > 20:
        return False, f"ë„ˆë¬´ ê¸´ í…ìŠ¤íŠ¸: '{text[:20]}...' (len: {len(text_clean)})"
    
    # ì´ë¯¸ì§€ í¬ê¸° ê¸°ë°˜ ë™ì  ì„ê³„ê°’ ê³„ì‚°
    # ê¸°ì¤€ í•´ìƒë„: 1920x1080
    base_width, base_height = 1920, 1080
    width_scale = img_width / base_width
    height_scale = img_height / base_height
    
    # ìµœì†Œ í¬ê¸° (ì´ë¯¸ì§€ í¬ê¸°ì— ë¹„ë¡€)
    min_height = max(5, int(12 * height_scale))
    min_width = max(5, int(15 * width_scale))
    if crop_height < min_height or crop_width < min_width:
        return False, f"ë„ˆë¬´ ì‘ì€ crop: {text} ({crop_width}x{crop_height}, ê¸°ì¤€: {min_width}x{min_height})"
    
    # ì¢…íš¡ë¹„ ì²´í¬ (ì¼ì •)
    aspect_ratio = crop_width / crop_height
    if aspect_ratio > 20:
        return False, f"ë„ˆë¬´ ê°€ëŠ˜ê²Œ ê¸´ crop: {text} (ratio: {aspect_ratio:.2f})"
    
    if aspect_ratio < 0.05:
        return False, f"ë„ˆë¬´ ë‚©ì‘í•œ crop: {text} (ratio: {aspect_ratio:.2f})"
    
    return True, "PASS"


def visualize_bbox_detection(img_path: Path, crops: List[Tuple[str, float, List[Tuple[int, int]]]], 
                            img_bgr: np.ndarray, padding_ratio: float = 0.3) -> None:
    """
    OCR ê²°ê³¼ì™€ bboxë¥¼ ì‹œê°í™”í•˜ì—¬ ê²€ì¦
    """
    # RGBë¡œ ë³€í™˜
    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
    img_height, img_width = img_bgr.shape[:2]
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))
    
    # ì›ë³¸ ì´ë¯¸ì§€ + ì›ë˜ bbox
    ax1.imshow(img_rgb)
    ax1.set_title(f'Original Bboxes: {img_path.name}\n({len(crops)} detections)', fontsize=14)
    ax1.axis('off')
    
    # íŒ¨ë”© ì ìš©ëœ ì´ë¯¸ì§€ + í™•ì¥ëœ bbox
    ax2.imshow(img_rgb)
    ax2.set_title(f'Padded Bboxes (padding: {padding_ratio*100}%)', fontsize=14)
    ax2.axis('off')
    
    valid_count = 0
    filtered_count = 0
    
    for i, (text, conf, verts) in enumerate(crops):
        # ì›ë˜ bbox ê·¸ë¦¬ê¸°
        xs, ys = zip(*[(int(x), int(y)) for x, y in verts])
        x0_orig, y0_orig, x1_orig, y1_orig = min(xs), min(ys), max(xs), max(ys)
        
        rect1 = patches.Rectangle((x0_orig, y0_orig), x1_orig-x0_orig, y1_orig-y0_orig, 
                                 linewidth=2, edgecolor='red', facecolor='none')
        ax1.add_patch(rect1)
        ax1.text(x0_orig, y0_orig-5, f'{i}: {text[:10]}', fontsize=8, color='red', 
                bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.7))
        
        # íŒ¨ë”© ì ìš©ëœ bbox
        x0_pad, y0_pad, x1_pad, y1_pad = expand_bbox_with_padding(
            verts, img_height, img_width, padding_ratio
        )
        
        # í’ˆì§ˆ ê²€ì‚¬
        crop_width = x1_pad - x0_pad
        crop_height = y1_pad - y0_pad
        is_valid, reason = is_valid_crop(text, crop_width, crop_height, img_width, img_height)
        
        if is_valid:
            color = 'green'
            valid_count += 1
            status = 'âœ“'
        else:
            color = 'orange'
            filtered_count += 1
            status = 'âœ—'
        
        rect2 = patches.Rectangle((x0_pad, y0_pad), crop_width, crop_height, 
                                 linewidth=2, edgecolor=color, facecolor='none')
        ax2.add_patch(rect2)
        ax2.text(x0_pad, y0_pad-5, f'{i}{status}: {text[:10]}', fontsize=8, color=color,
                bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.7))
    
    # í†µê³„ ì •ë³´ ì¶”ê°€
    fig.suptitle(f'Valid: {valid_count}, Filtered: {filtered_count}, Total: {len(crops)}', 
                fontsize=16, fontweight='bold')
    
    plt.tight_layout()
    plt.show()
    
    # í•„í„°ë§ëœ í•­ëª©ë“¤ì˜ ì´ìœ  ì¶œë ¥
    print(f"\n[DEBUG] {img_path.name} ìƒì„¸ ë¶„ì„:")
    for i, (text, conf, verts) in enumerate(crops):
        x0_pad, y0_pad, x1_pad, y1_pad = expand_bbox_with_padding(
            verts, img_height, img_width, padding_ratio
        )
        crop_width = x1_pad - x0_pad
        crop_height = y1_pad - y0_pad
        is_valid, reason = is_valid_crop(text, crop_width, crop_height, img_width, img_height)
        
        status = "âœ“ PASS" if is_valid else f"âœ— FILTER: {reason}"
        print(f"  {i:2d}. '{text}' ({crop_width}x{crop_height}, conf:{conf:.2f}) â†’ {status}")
    print()


def get_all_images_from_categories(base_path: Path) -> List[Path]:
    """
    ì—¬ëŸ¬ ì¹´í…Œê³ ë¦¬ í´ë”ì—ì„œ ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ìˆ˜ì§‘
    """
    categories = ['image', 'notice', 'handwriting']
    all_images = []
    
    for category in categories:
        category_path = base_path / category
        if category_path.exists():
            # ì´ë¯¸ì§€ íŒŒì¼ í™•ì¥ìë“¤
            extensions = ['*.png', '*.jpg', '*.jpeg', '*.PNG', '*.JPG', '*.JPEG']
            for ext in extensions:
                all_images.extend(category_path.glob(ext))
            print(f"  {category}: {len(list(category_path.glob('*')))}ê°œ íŒŒì¼ ë°œê²¬")
        else:
            print(f"  {category}: í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ")
    
    return sorted(all_images)


def debug_mode_processing(split_name: str, in_root: Path,
                          api_url: str, secret: str,
                          conf_th: float = 0.5,
                          padding_ratio: float = 0.3,
                          debug_count: int = 5):
    """
    ë””ë²„ê·¸ ëª¨ë“œì—ì„œ bbox ì‹œê°í™” ë° ê²€ì¦
    """
    img_paths = get_all_images_from_categories(in_root)[:debug_count]
    print(f"[DEBUG] {split_name} â†’ {len(img_paths)}ì¥ í…ŒìŠ¤íŠ¸")

    for i, img_fp in enumerate(img_paths):
        print(f"\n[DEBUG {i+1}/{len(img_paths)}] {img_fp.name} ({img_fp.parent.name}) ì²˜ë¦¬ ì¤‘...")

        # 1ï¸âƒ£ ì´ë¯¸ì§€ ì½ê¸° (ì›ë³¸ ê·¸ëŒ€ë¡œ)
        img_bgr = cv2.imread(str(img_fp))
        if img_bgr is None:
            print("  âš ï¸ ì´ë¯¸ì§€ ì½ê¸° ì‹¤íŒ¨")
            continue

        # 2ï¸âƒ£ OCR ìˆ˜í–‰ (ì›ë³¸ ì´ë¯¸ì§€ë¡œ)
        resp = clova_ocr_api(img_fp, api_url, secret)
        crops = parse_fields(resp, conf_th)

        if not crops:
            print("  OCR ê²°ê³¼ ì—†ìŒ")
            continue

        # 3ï¸âƒ£ bbox ì‹œê°í™”
        visualize_bbox_detection(img_fp, crops, img_bgr, padding_ratio)

        # 4ï¸âƒ£ ê³„ì† ì§„í–‰ ì—¬ë¶€ í™•ì¸
        key = input("Enter=ê³„ì†   q=ì¢…ë£Œ   s=ì „ì²´ì‹¤í–‰ : ").strip().lower()
        if key == "q":
            return False
        elif key == "s":
            return True
        time.sleep(0.2)
    
    return True


def process_split_enhanced(split_name: str,
                           in_root: Path,
                           out_root: Path,
                           api_url: str, secret: str,
                           conf_th: float = 0.5,
                           padding_ratio: float = 0.3,
                           enhancement_level: str = "medium",
                           reader=None,                # â˜… ì¶”ê°€
                           min_rec_conf: float = 0.18  # â˜… ì¶”ê°€
                           ):
   """
   í–¥ìƒëœ crop ì²˜ë¦¬ê°€ í¬í•¨ëœ split ì²˜ë¦¬ í•¨ìˆ˜ - ë””ë²„ê¹… ê°•í™”
   """
   if reader:
     recog     = reader.recognizer
     converter = reader.converter
     opt2val   = reader.opt2val
        
   out_img_dir = out_root / "merged_images"
   out_img_dir.mkdir(parents=True, exist_ok=True)

   csv_rows: List[Tuple[str,str,str]] = []
   out_index = 0
   
   # í†µê³„ ì¹´ìš´í„°
   stats = {
       'total_detected': 0,
       'filtered_out': 0,
       'saved': 0,
       'enhancement_failed': 0,
       'ocr_failed': 0,
       'image_load_failed': 0,
       'filter_reasons': {},
       'category_stats': {'image': 0, 'notice': 0, 'handwriting': 0}
   }

   # ëª¨ë“  ì¹´í…Œê³ ë¦¬ì—ì„œ ì´ë¯¸ì§€ ìˆ˜ì§‘
   img_paths = get_all_images_from_categories(in_root)
   print(f"[{split_name}] ì´ ì²˜ë¦¬í•  ì´ë¯¸ì§€ ìˆ˜: {len(img_paths)}")
   print(f"[{split_name}] í–¥ìƒ ìˆ˜ì¤€: {enhancement_level}")
   
   # CSV íŒŒì¼ ê²½ë¡œ ë¯¸ë¦¬ ì„¤ì •
   out_csv = out_root / f"{split_name}_labels_2.csv"
   
   for i, img_fp in enumerate(img_paths):
       # ë§¤ ì´ë¯¸ì§€ë§ˆë‹¤ ì§„í–‰ë¥  ì¶œë ¥ (ë””ë²„ê¹…ìš©)
       print(f"\n[{split_name}] ì§„í–‰ë¥ : {i+1}/{len(img_paths)} - {img_fp.name} ({img_fp.parent.name})")
       
       category = img_fp.parent.name
       
       try:
           # OCR ìˆ˜í–‰
           print(f"  1) OCR ìˆ˜í–‰ ì¤‘...")
           resp = clova_ocr_api(img_fp, api_url, secret)
           
           if resp is None:
               print(f"  â†’ OCR ì‹¤íŒ¨, ë‹¤ìŒ ì´ë¯¸ì§€ë¡œ...")
               stats['ocr_failed'] += 1
               continue
               
           crops = parse_fields(resp, conf_th)
           print(f"  â†’ {len(crops)}ê°œ í…ìŠ¤íŠ¸ ì˜ì—­ ê²€ì¶œ")

           if not crops:
               print(f"  â†’ ê²€ì¶œëœ í…ìŠ¤íŠ¸ ì—†ìŒ, ë‹¤ìŒ ì´ë¯¸ì§€ë¡œ...")
               continue

           # ì›ë³¸ ì´ë¯¸ì§€ ì½ê¸°
           print(f"  2) ì´ë¯¸ì§€ ë¡œë“œ ì¤‘...")
           img_bgr = cv2.imread(str(img_fp))
           if img_bgr is None:
               print(f"  â†’ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨, ë‹¤ìŒ ì´ë¯¸ì§€ë¡œ...")
               stats['image_load_failed'] += 1
               continue
               
           img_height, img_width = img_bgr.shape[:2]
           print(f"  â†’ ì´ë¯¸ì§€ í¬ê¸°: {img_width}x{img_height}")

           # crop ì²˜ë¦¬
           print(f"  3) crop ì²˜ë¦¬ ì¤‘...")
           valid_crops = 0
           
           for j, (text, conf, verts) in enumerate(crops):
               stats['total_detected'] += 1
               
               print(f"    ì²˜ë¦¬ ì¤‘: '{text}' (conf: {conf:.2f})")
               
               # bbox í™•ì¥
               x0, y0, x1, y1 = expand_bbox_with_padding(
                   verts, img_height, img_width, padding_ratio
               )
               
               crop = img_bgr[y0:y1, x0:x1]
               if crop.size == 0: 
                   print(f"    â†’ ë¹ˆ crop, ìŠ¤í‚µ")
                   stats['filtered_out'] += 1
                   continue
                   
               # í’ˆì§ˆ ê²€ì‚¬
               crop_height, crop_width = crop.shape[:2]
               is_valid, reason = is_valid_crop(text, crop_width, crop_height, img_width, img_height)
               
               if not is_valid:
                   print(f"    â†’ í•„í„°ë§: {reason}")
                   stats['filtered_out'] += 1
                   filter_type = reason.split(':')[0]
                   stats['filter_reasons'][filter_type] = stats['filter_reasons'].get(filter_type, 0) + 1
                   continue
               
               if reader:
                    # crop â†’ uint8 gray
                    gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY) if crop.ndim == 3 else crop
                    pr_txt, rec_conf = recognize_imgs([gray], recog, converter, opt2val)[0]
                    if rec_conf < min_rec_conf:
                        print(f"    â†’ recognizer conf {rec_conf:.2f} < {min_rec_conf}, skip")
                        stats['filtered_out'] += 1
                        stats['filter_reasons']['low_rec_conf'] = \
                            stats['filter_reasons'].get('low_rec_conf', 0) + 1
                        continue

               # í–¥ìƒëœ crop ì €ì¥
               fname = f"{out_index:06d}.png"
               save_path = str(out_img_dir / fname)
               
               if save_enhanced_crop(crop, save_path, enhancement_level):
                   csv_rows.append((fname, text, category))
                   out_index += 1
                   stats['saved'] += 1
                   stats['category_stats'][category] += 1
                   valid_crops += 1
                   # print(f"    â†’ ì €ì¥ ì„±ê³µ: {fname}")
               else:
                   # print(f"    â†’ ì €ì¥ ì‹¤íŒ¨: {text}")
                   stats['enhancement_failed'] += 1

           print(f"  â†’ {valid_crops}ê°œ crop ì €ì¥ ì™„ë£Œ")
           
       except KeyboardInterrupt:
           print(f"\nì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨. í˜„ì¬ê¹Œì§€ ê²°ê³¼ ì €ì¥ ì¤‘...")
           # ì¤‘ë‹¨ ì‹œ í˜„ì¬ê¹Œì§€ ì €ì¥
           if csv_rows:
               with out_csv.open("w", newline="", encoding="utf-8") as fp:
                   wr = csv.writer(fp)
                   wr.writerow(["filename", "text", "category"])
                   wr.writerows(csv_rows)
               print(f"ì¤‘ë‹¨ ì‹œì ê¹Œì§€ ì €ì¥ ì™„ë£Œ: {out_csv}")
           break
       except Exception as e:
           print(f"  ì˜¤ë¥˜ ë°œìƒ: {e}")
           print(f"  â†’ ë‹¤ìŒ ì´ë¯¸ì§€ë¡œ ê³„ì†...")
           continue

       # API í˜¸ì¶œ ê°„ê²© ì¡°ì •
       print(f"  4) API í˜¸ì¶œ ê°„ê²© ëŒ€ê¸°...")
       time.sleep(0.5)
       
       # 500ì¥ë§ˆë‹¤ CSV ì—…ë°ì´íŠ¸
       if (i + 1) % 500 == 0:
           print(f"  ğŸ“ CSV ì—…ë°ì´íŠ¸ ì¤‘... ({i + 1}/{len(img_paths)})")
           with out_csv.open("w", newline="", encoding="utf-8") as fp:
               wr = csv.writer(fp)
               wr.writerow(["filename", "text", "category"])
               wr.writerows(csv_rows)
           print(f"  âœ… CSV ì—…ë°ì´íŠ¸ ì™„ë£Œ: {out_csv} ({len(csv_rows)}ê°œ í•­ëª©)")

   # ìµœì¢… CSV ì €ì¥
   print(f"\n[{split_name}] ìµœì¢… CSV ì €ì¥ ì¤‘...")
   with out_csv.open("w", newline="", encoding="utf-8") as fp:
       wr = csv.writer(fp)
       wr.writerow(["filename", "text", "category"])
       wr.writerows(csv_rows)
   
   # í†µê³„ ì¶œë ¥
   print(f"\n[{split_name}] ì²˜ë¦¬ ì™„ë£Œ í†µê³„:")
   print(f"  ì´ ê²€ì¶œëœ í…ìŠ¤íŠ¸: {stats['total_detected']}ê°œ")
   print(f"  í•„í„°ë§ëœ í…ìŠ¤íŠ¸: {stats['filtered_out']}ê°œ") 
   print(f"  ì €ì¥ëœ crop: {stats['saved']}ê°œ")
   print(f"  í–¥ìƒ ì²˜ë¦¬ ì‹¤íŒ¨: {stats['enhancement_failed']}ê°œ")
   print(f"  í–¥ìƒ ìˆ˜ì¤€: {enhancement_level}")
   
   print(f"  ì¹´í…Œê³ ë¦¬ë³„ ì €ì¥ í†µê³„:")
   for cat, count in stats['category_stats'].items():
       print(f"    {cat}: {count}ê°œ")
   
   if stats['filter_reasons']:
       print(f"  í•„í„°ë§ ì´ìœ ë³„ í†µê³„:")
       for reason, count in stats['filter_reasons'].items():
           print(f"    {reason}: {count}ê°œ")
   
   print(f"  CSV ì €ì¥: {out_csv}")
   print(f"  ì´ë¯¸ì§€ ì €ì¥: {out_img_dir}")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2.  main
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    load_dotenv()
    api_url   = os.environ["API_URL"]
    secret    = os.environ["SECRET_KEY"]
    
    reader = brainocr.Reader(
        lang="ko",
        det_model_ckpt_fp="pororo/misc/craft.pt",          # detector ê·¸ëŒ€ë¡œ
        rec_model_ckpt_fp="assets/finetune_clova.pt",      # â† í•™ìŠµí•œ ckpt
        opt_fp="assets/finetune_clova_opt.txt",
        device="cuda",
    )
    
    min_rec_conf = float(input("brainOCR ìµœì†Œ confidence? (ê¸°ë³¸ 0.18): ") or 0.18)

    # ì‚¬ìš©ì ì„¤ì •
    print("=== Crop ì´ë¯¸ì§€ í–¥ìƒ ì„¤ì • ===")
    print("1. light   - 64px ë†’ì´, ê¸°ë³¸ ëŒ€ë¹„ í–¥ìƒ")
    print("2. medium  - 96px ë†’ì´, ëŒ€ë¹„+ìƒ¤í”„ë‹+ë…¸ì´ì¦ˆì œê±°")  
    print("3. heavy   - 128px ë†’ì´, ëª¨ë“  í–¥ìƒ ê¸°ëŠ¥")
    
    enhancement_choice = input("í–¥ìƒ ìˆ˜ì¤€ ì„ íƒ (1-3, ê¸°ë³¸ê°’ 2): ").strip()
    enhancement_map = {"1": "light", "2": "medium", "3": "heavy"}
    enhancement_level = enhancement_map.get(enhancement_choice, "medium")
    
    # íŒ¨ë”© ì„¤ì •
    padding_input = input("íŒ¨ë”© ë¹„ìœ¨ ì…ë ¥ (0.01-0.5, ê¸°ë³¸ê°’ 0.3): ").strip()
    try:
        padding_ratio = float(padding_input)
        padding_ratio = max(0.01, min(0.5, padding_ratio))  # 0.1~0.5 ë²”ìœ„ë¡œ ì œí•œ
    except:
        padding_ratio = 0.01
    
    print(f"\nì„ íƒëœ ì„¤ì •:")
    print(f"  í–¥ìƒ ìˆ˜ì¤€: {enhancement_level}")
    print(f"  íŒ¨ë”© ë¹„ìœ¨: {padding_ratio*100}%")
    
    enhancement_details = {
        "light": "64px, ëŒ€ë¹„í–¥ìƒë§Œ",
        "medium": "96px, ëŒ€ë¹„+ìƒ¤í”„ë‹+ë…¸ì´ì¦ˆì œê±°", 
        "heavy": "128px, ëª¨ë“  í–¥ìƒê¸°ëŠ¥"
    }
    print(f"  ìƒì„¸ ì„¤ì •: {enhancement_details[enhancement_level]}")
    print("=" * 50)
    
    # ë””ë²„ê·¸ ëª¨ë“œ ì˜µì…˜
    debug_mode = input("\në””ë²„ê·¸ ëª¨ë“œë¡œ bbox í™•ì¸? (y/N): ").strip().lower() == 'y'
    
    splits = [("train", Path("train_2"), Path("CLOVA_V2_train")),
              ("test" , Path("test_2") , Path("CLOVA_V2_test"))]

    for name, src, dst in splits:
        print(f"\n[ì‹œì‘] {name} ì²˜ë¦¬ ì¤‘...")
        print(f"ì…ë ¥ ê²½ë¡œ: {src}")
        
        # ì¹´í…Œê³ ë¦¬ë³„ ì´ë¯¸ì§€ ìˆ˜ í™•ì¸
        total_images = get_all_images_from_categories(src)
        if not total_images:
            print(f"âš ï¸  {src}ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            continue
            
        print(f"ì´ {len(total_images)}ê°œ ì´ë¯¸ì§€ ë°œê²¬")
        
        if debug_mode:
            # ë””ë²„ê·¸ ëª¨ë“œë¡œ ì‹œê°í™”
            should_continue = debug_mode_processing(name, src, api_url, secret, 
                                                  conf_th=0.5, padding_ratio=padding_ratio)
            if not should_continue:
                continue
        
        # í–¥ìƒëœ ì²˜ë¦¬ ëª¨ë“œ ì‚¬ìš©
        process_split_enhanced(name, src, dst, api_url, secret,
                       conf_th=0.5,
                       padding_ratio=padding_ratio,
                       enhancement_level=enhancement_level,
                       reader=reader,              # â˜… ì¶”ê°€
                       min_rec_conf=min_rec_conf)  # â˜… ì¶”ê°€
        print(f"[ì™„ë£Œ] {name} ì²˜ë¦¬ ì™„ë£Œ\n")

    print("\nğŸ‰ ëª¨ë“  ì²˜ë¦¬ ì™„ë£Œ!")
    print(f"ğŸ’¡ í–¥ìƒëœ crop ì´ë¯¸ì§€ë“¤ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤ (ìˆ˜ì¤€: {enhancement_level})")


if __name__ == "__main__":
    main()